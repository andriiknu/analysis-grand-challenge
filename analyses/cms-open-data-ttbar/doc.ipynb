{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09aaae2",
   "metadata": {},
   "source": [
    "# $t\\bar{t}$-analysis\n",
    "The chapter covers the $t\\bar{t}$-analysis logic. [2015 CMS Open Data](https://cms.cern/news/first-cms-open-data-lhc-run-2-released) is assumed as input data for concreteness (see **Links for download** section). The basic idea of this chapter is to give a basic algorithm for distinguishing the t-quark pair production channel among other concurrent channels (production of single t-quark and w-jet) and to get the mass peak of the t-quark using a histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ca5fb4",
   "metadata": {},
   "source": [
    "## Input\n",
    "Input data is five sets of root-files. Each set is produced in MC simulation and represents a partial interaction channel, one of five: $t\\bar{t}$-channel, *single top s*-channel, *single top t*-channel, *single top tW*-channel, *Wjets*-channel. \n",
    "The root-file structure can be represented as a schematic:\n",
    "\\\n",
    "\\\n",
    "<img src=\"images/input_structer.png\" width=\"600\" height=\"300\">\n",
    "\\\n",
    "This diagram shows only those fields that will be required for further analysis, such as electron, muon, and jet. Each of these branches has its number of particles ($N_e$, $N_{\\mu}$, $N_{jet}$), the transverse momentum value ($P_\\mathrm{T}$) that will be used in the following sections for events filtering. Also, jets have a b-tag value, which is the output of a discriminator used to identify b-jets (jets produced by b-quark)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7f3c8a",
   "metadata": {},
   "source": [
    "## Output\n",
    "The analysis task is selecting events from the whole input data set, in which measured quantities originated from $t\\bar{t}$-decay. In real data, one can not exactly know in which event $t\\bar{t}$-pair were produced. But since we have simulated data, we know exactly whether or not $t\\bar{t}$ in any particular event. That is defined by the set to which the file belongs, as was mentioned above. As five channels were involved, five different sets were generated and are given as input data (*ttbar*, *single_top_s_chan*, *single_top_t_chan*, *single_top_tW*, *wjets*).\n",
    "To select events we will apply some criteria (explained below) and then compare the relative rate of those events which indeed were generated with $t\\bar{t}$-quark pair production. The example below demonstrate successfully performed $t\\bar{t}$ analysis. That is concluded from the fact, that most of the selected events indeed belong to $t\\bar{t}$-channel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aa37c6",
   "metadata": {},
   "source": [
    "<img src=\"images/analysis.png\" width=500 hight=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7d4300",
   "metadata": {},
   "source": [
    "## Events filtering algorithm\n",
    "Not all particles with their quantities are needed for doing analysis. The only ones to which selection criteria will be applied are leptons (electrons and muons) and jets that are the products of $t\\bar{t}$ decay. In the semi-leptonic decay channel of $t\\bar{t}$ production, two jets, two b-jets, and one outgoing lepton are expected, as can be concluded from the diagram below:\n",
    "\n",
    "<img src=images/ttbardecay.png hight = 400 width = 400 >\n",
    "\n",
    "So, events that belong to semi-leptonic $t\\bar{t}$ decay mode can be identified by the presence of those products: one lepton, two jets, and two b-tag jets. This is the foundation of the algorithm presented below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9184a17",
   "metadata": {},
   "source": [
    "### 1. Filtering particles by transverse momentum threshold\n",
    "\n",
    "It is expected that the first step has to be the selection of those events that have at least one lepton and four jets, according to the decay schema. But, before we go any further, one significant thing must be noted.\n",
    "\n",
    "The note is that some electrons, muons, and jets must be excluded from the analysis procedure. That means some particles will not be considered as potential decay products, and all further actions will not relate to them. \n",
    "\n",
    "The transverse momentum ($P_\\mathrm{T}$) of appropriative electrons, muons, and jets must be higher than some threshold value.\n",
    "\n",
    "It is well suggested to set a threshold of 25 GeV. One can test any other value, but it must be high enough to distinguish collision events from diffractive scattering events and must not be too large to avoid losing a significant amount of interesting events.  \n",
    "\n",
    "This step can be understood as the following input$\\Rightarrow$output transformation:\n",
    "* input: every row contains a full number of particles\n",
    "* output: every row contains muons, electrons and jets with appropriate transverse momentum value ($P_\\mathrm{T} > 25$ GeV) per event.\n",
    "\n",
    "So, this action is identical to defining new branches containing only appropriative particles. All further actions are described assuming that the user define new branches like as muon($P_\\mathrm{T, e}>25$ GeV), electron($P_\\mathrm{T, \\mu}> 25$ GeV) and jets($P_\\mathrm{T, jet}>25$ GeV) or take care about transverse momentum of particles in each step in its own way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7056fa2",
   "metadata": {},
   "source": [
    "### 2.  Filtering events by lepton and jet numbers\n",
    "Then events that contain only one lepton (exactly one electron or exactly one muon) and four or more jets must be selected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7326f9f2",
   "metadata": {},
   "source": [
    "### 3. Filtering events by jet b-tagging\n",
    "Next, events that contain at least two b-tagged jets must be selected. Setting a b-tag threshold equal to 0.5 is well suggested. So, the output is only those events that contain at least two jets with a b-tag value higher than 0.5.\\\n",
    "The b-tag threshold also is not fixed as well as $P_\\mathrm{T}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a635a7",
   "metadata": {},
   "source": [
    "## $t$-quark mass plotting\n",
    "For this moment, one had to leave only appropriate events for our analysis. \n",
    "The final task is plotting $t$-quark mass. As shown in the $t\\bar{t}$-decay diagram, the first $t$-quark decayed into $b$-quark, lepton, and neutrino, while the second ${t}$-quark ($\\bar{t}$-quark) into two quarks and one $b$-quark. Consequently, the $t$-quark mass can be restored by those products: one b-quark and two quarks, so three jets are needed for $t$-quark mass plotting.\\\n",
    "Consequently, to plot mass, it is necessary to find all possible trijet combinations per event and select the most appropriate one. Required properties are the highest total transverse momentum value and at least one b-tagged jet. So, at the output to each event will be assigned a sample of three jets with those requirements:\n",
    "* The maximal total $P_\\mathrm{T}$\n",
    "* At least one jet is ***b-tagged***\n",
    "\n",
    "At this point, all is ready to plot trijet mass and to get a similar $t$-quark peak as shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291b7fc",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Here is a brief cheat sheet for performing $t\\bar{t}$ analysis:\n",
    "\n",
    "### 1. Select events by following criteria:\n",
    "1. Transverse momentum of each of the further selected particles must be more than 25 GeV\n",
    "2. Single lepton, at least four jets\n",
    "3. At least two b-tagged jets (b-tag value threshold can equal 0.5)\n",
    "\n",
    "### 2. Build all possible trijet combinations per every event and leave single more appropriative by following criteria:\n",
    "1. At least one jet in a three-jet set must have a b-tag value more than the threshold (0.5)\n",
    "2. Trijet $P_\\mathrm{T}$ value must be the largest among all combinations per event.\n",
    "\n",
    "\n",
    "### 3. Graphical schema\n",
    "\n",
    "<img src=\"images/pipeline.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05775ff",
   "metadata": {},
   "source": [
    "## Weighting\n",
    "The above-described algorithm assumes that data samples generated using different channels come into the histogram with equivalent weights. It is not the case, as various data samples are not with equal numbers of events. Also, partial cross-section values must be taken into account. So we need to decrease weight with an increasing total number of events and increase ones with increasing cross-sections for normalization. This yields the formula:\n",
    "$$w_i = {{\\sigma}_i L \\over N_i}$$\\\n",
    "where $i$ represents partial interaction channel,\\\n",
    "$\\sigma_i$ - is partial cross-section,\\\n",
    "$L$ - is luminosity,\\\n",
    "$N_i$ - is the total number of events in the data sample.\\\n",
    "$L$=3378 $pb^{-1}$. Correct cross-section values for five interaction channels can be found [here](https://atlas-groupdata.web.cern.ch/atlas-groupdata/dev/AnalysisTop/TopDataPreparation/XSection-MC15-13TeV.data) and are presented below:\n",
    "* \"ttbar\": 729.84 pb\n",
    "* \"single_top_s_chan\": 3.2944 pb\n",
    "* \"single_top_t_chan\": 234.7936 pb\n",
    "* \"single_top_tW\": 75.842 pb,\n",
    "* \"wjets\": 15487.164 pb\\\n",
    "\n",
    "Those $w_i$ values are the weights that accord to different data samples generated using different interaction channels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da44082",
   "metadata": {},
   "source": [
    "## Variations\n",
    "The last part of this description is the variations section. The motivation for variations calculations is that output histograms are transferring further to statistical processing. That is not described here, but what is going on - the data is fitting according to the defined statistical model with some parameters. A statistical model describes input data and allows correctly determine observable quantities, for example, t-quark mass which means the mean value and uncertainty.\n",
    "\n",
    "Two values must be assigned to every bin - mean value and uncertainty. Assume we have N counts inside some bin. This is the mean value. According to Poisson distribution, the standard uncertainty is $\\sqrt{N}$. This means the weight in which bin will come into the statistical model.\n",
    "\n",
    "For correct mass of $t$-quark estimating one need to have those uncertainties as shown in example below:\n",
    "\n",
    "<img src=\"images/jetvar.png\" hight=500 width=500>\n",
    "\n",
    "Uncertainties here are determined by Poisson distribution ($\\sqrt{N}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3589e98",
   "metadata": {},
   "source": [
    "## Linsk for download:\n",
    "### Samples categorized by process\n",
    "\n",
    "- **ttbar**:\n",
    "  - nominal:\n",
    "    - [19980](https://opendata.cern.ch/record/19980): Powheg + Pythia 8 (ext3), 2413 files, 3.4 TB -> converted\n",
    "    - [19981](https://opendata.cern.ch/record/19981): Powheg + Pythia 8 (ext4), 4653 files, 6.4 TB -> converted\n",
    "  - scale variation:\n",
    "    - [19982](https://opendata.cern.ch/record/19982): same as below, unclear if overlap\n",
    "    - [19983](https://opendata.cern.ch/record/19983): Powheg + Pythia 8 \"scaledown\" (ext3), 902 files, 1.4 TB -> converted\n",
    "    - [19984](https://opendata.cern.ch/record/19984): same as below, unclear if overlap\n",
    "    - [19985](https://opendata.cern.ch/record/19985): Powheg + Pythia 8 \"scaleup\" (ext3), 917 files, 1.3 TB -> converted\n",
    "  - ME variation:\n",
    "    - [19977](https://opendata.cern.ch/record/19977): same as below, unclear if overlap\n",
    "    - [19978](https://opendata.cern.ch/record/19978): aMC@NLO + Pythia 8 (ext1), 438 files, 647 GB -> converted\n",
    "  - PS variation:\n",
    "    - [19999](https://opendata.cern.ch/record/19999): Powheg + Herwig++, 443 files, 810 GB -> converted\n",
    "\n",
    "- **single top**:\n",
    "  - s-channel:\n",
    "    - [19394](https://opendata.cern.ch/record/19394): aMC@NLO + Pythia 8, 114 files, 76 GB -> converted\n",
    "  - t-channel:\n",
    "    - [19406](https://opendata.cern.ch/record/19406): Powheg + Pythia 8 (antitop), 935 files, 1.1 TB -> converted\n",
    "    - [19408](https://opendata.cern.ch/record/19408): Powheg + Pythia 8 (top), 1571 files, 1.8 TB -> converted\n",
    "  - tW:\n",
    "    - [19412](https://opendata.cern.ch/record/19412): Powheg + Pythia 8 (antitop), 27 files, 30 GB -> converted\n",
    "    - [19419](https://opendata.cern.ch/record/19419): Powheg + Pythia 8 (top), 23 files, 30 GB -> converted\n",
    "\n",
    "- **W+jets**:\n",
    "  - nominal (with 1l filter):\n",
    "    - [20546](https://opendata.cern.ch/record/20546): same as below, unclear if overlap\n",
    "    - [20547](https://opendata.cern.ch/record/20547): aMC@NLO + Pythia 8 (ext2), 5601 files, 4.5 TB -> converted\n",
    "    - [20548](https://opendata.cern.ch/record/20548): aMC@NLO + Pythia 8 (ext4), 4598 files, 3.8 TB -> converted\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
